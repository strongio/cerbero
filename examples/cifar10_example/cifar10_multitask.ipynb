{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Multi-Task\n",
    "\n",
    "In this example we're going to build the common exercise of building a CIFAR-10 classifier but with a multi-task twist: in addition to predicting the class, we're also going to estimate the average RGB values of each image.\n",
    "This will turn our classic classification example into a classification and regression multi-task learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# NOTE: for dev purposes add package to path\n",
    "cerbero_path = os.path.normpath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(cerbero_path)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset is a set of 3-channel color images of 32x32 pixels in size.\n",
    "Each image is labeled with one of the following classes:  ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
    "\n",
    "In addition to predicting the correct label for each image we're also going to estimate the average RGB color for each image. For this we'll have to do a bit of additional preprocessing to get to the following dataset:\n",
    "\n",
    "- input: [3,32,32] float tensor of normalized range [-1,1]\n",
    "- targets:\n",
    "  - class label: int [0,9]\n",
    "  - rgb: 3-element vector of range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfed4f8ffb24920b7ed862f22d778d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc227e69e2b04db8b1c7b238407d6e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import make_cifar_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "((class_images_train, class_labels_train),\n",
    " (rgb_images_train, rgb_labels_train))= make_cifar_dataset(train=True)\n",
    "\n",
    "# Further split train into train/test\n",
    "(class_images_train,\n",
    " class_images_test,\n",
    " class_labels_train,\n",
    " class_labels_test) = train_test_split(\n",
    "    class_images_train, class_labels_train, test_size=0.05)\n",
    "\n",
    "(rgb_images_train,\n",
    " rgb_images_test,\n",
    " rgb_labels_train,\n",
    " rgb_labels_test) = train_test_split(\n",
    "    rgb_images_train, rgb_labels_train, test_size=0.1)\n",
    "\n",
    "((class_images_val, class_labels_val),\n",
    " (rgb_images_val, rgb_labels_val)) = make_cifar_dataset(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now group our datasets into dictionaries with the tasks as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = {}, {}, {}\n",
    "Y_train, Y_val, Y_test = {}, {}, {}\n",
    "\n",
    "# Label class dataset\n",
    "X_train[\"class\"] = class_images_train\n",
    "Y_train[\"class\"] = class_labels_train\n",
    "X_test[\"class\"] = class_images_test\n",
    "Y_test[\"class\"] = class_labels_test\n",
    "X_val[\"class\"] = class_images_val\n",
    "Y_val[\"class\"] = class_labels_val\n",
    "\n",
    "\n",
    "# RGB dataset\n",
    "X_train[\"rgb\"] = rgb_images_train\n",
    "Y_train[\"rgb\"] = rgb_labels_train\n",
    "X_test[\"rgb\"] = rgb_images_test\n",
    "Y_test[\"rgb\"] = rgb_labels_test\n",
    "X_val[\"rgb\"] = rgb_images_val\n",
    "Y_val[\"rgb\"] = rgb_labels_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data now loaded/created, we can now package it up into `DictDataset` objects for training.\n",
    "This object is a simple wrapper around `torch.utils.data.Dataset` and stored data fields and labels as dictionaries.\n",
    "\n",
    "In the `DictDataset`, each label corresponds to a particular `Task` by name. We'll define these `Task` objects in the following section as we define our model.\n",
    "\n",
    "`DictDataLoader` is a wrapper for `torch.utils.data.DataLoader`, which handles the collate function for `DictDataset` appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerbero.core import DictDataset, DictDataLoader\n",
    "\n",
    "dataloaders = []\n",
    "for task_name in [\"class\", \"rgb\"]:\n",
    "    for split, X, Y in (\n",
    "        (\"train\", X_train, Y_train),\n",
    "        (\"valid\", X_val, Y_val),\n",
    "        (\"test\", X_test, Y_test)\n",
    "    ):\n",
    "        X_dict = {f\"{task_name}_data\": torch.FloatTensor(X[task_name])}\n",
    "        YTensor = torch.FloatTensor if task_name == \"rgb\" else torch.LongTensor\n",
    "        Y_dict = {f\"{task_name}_task\": YTensor(Y[task_name])}\n",
    "        dataset = DictDataset(f\"{task_name}Dataset\", split, X_dict, Y_dict)\n",
    "        dataloader = DictDataLoader(dataset, batch_size=32)\n",
    "        dataloaders.append(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 4 data loaders, one for each split (`train`, `val`) of each task (`class_task` and `rgb_task`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define the `MultitaskClassifier` model, a PyTorch multi-task classifier. We'll instantiate it from a list of `Tasks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from cerbero.core import Operation\n",
    "\n",
    "# Define the base conv net and a one-layer prediction \"head\" module\n",
    "class BaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "base_net = BaseNet()\n",
    "class_head_module = nn.Linear(84, 10)\n",
    "\n",
    "# The module pool contains all the modules this task uses\n",
    "module_pool = nn.ModuleDict(\n",
    "    {\"base_net\": base_net, \"class_head_module\": class_head_module}\n",
    ")\n",
    "\n",
    "# Op1: pull data from \"class_data\" and send through base net\n",
    "op1 = Operation(\n",
    "    name=\"base_net\",\n",
    "    module_name=\"base_net\",\n",
    "    inputs=[(\"_input_\", \"class_data\")]\n",
    ")\n",
    "\n",
    "# Op2: pass output of Op1 to the class head module\n",
    "op2 = Operation(\n",
    "    name=\"class_head\",\n",
    "    module_name=\"class_head_module\",\n",
    "    inputs=[\"base_net\"]\n",
    ")\n",
    "\n",
    "op_sequence = [op1, op2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the final operation will then go into a loss function to calculate the loss (e.g., cross-entropy) during training or an output function (e.g., softmax) to convert the logits into a prediction.\n",
    "\n",
    "Each `Task` also specifies which metrics it supports, which are bundled together in a `Scorer` object. For this tutorial, we'll just look at accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from cerbero.metrics import Scorer\n",
    "from cerbero.core import Task\n",
    "\n",
    "class_task = Task(\n",
    "    name=\"class_task\",\n",
    "    module_pool=module_pool,\n",
    "    op_sequence=op_sequence,\n",
    "    loss_func=F.cross_entropy,\n",
    "    output_func=partial(F.softmax, dim=1),\n",
    "    scorer=Scorer(metrics=[\"accuracy\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, for the RGB `Task`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the RGB `Task` differs in that we'll be training the model to estimate the average RGB colors in the image which we model here as a regression task. Additonally, we'll define the RGB head as a two-layer module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RGBHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(84, 16)\n",
    "        self.fc2 = nn.Linear(16, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "rgb_head_module = RGBHead()\n",
    "\n",
    "op_sequence = [\n",
    "    Operation(\n",
    "        name=\"base_net\",\n",
    "        module_name=\"base_net\",\n",
    "        inputs=[(\"_input_\", \"rgb_data\")]\n",
    "    ),\n",
    "    Operation(\n",
    "        name=\"rgb_head\",\n",
    "        module_name=\"rgb_head_module\",\n",
    "        inputs=[\"base_net\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "def identity_fn(x):\n",
    "    return x\n",
    "\n",
    "rgb_task = Task(\n",
    "    name=\"rgb_task\",\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\"base_net\": base_net,\n",
    "         \"rgb_head_module\": rgb_head_module}\n",
    "    ),\n",
    "    op_sequence=op_sequence,\n",
    "    loss_func=F.mse_loss,\n",
    "    output_func=identity_fn,\n",
    "    scorer=Scorer(metrics=[\"mse\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our tasks defined, constructing a model is simple: we simply pass the list of tasks in and the model constructs itself using information from the task flows.\n",
    "\n",
    "Note that the model uses the names of modules (not the modules themselves) to determine whether two modules specified by separate tasks are the same module (and should share weights) or different modules (with separate weights).\n",
    "So because both the `class_task` and `rgb_task` include \"base_net\" in their module pools, this module will be shared between the two tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerbero.models import MultitaskClassifier\n",
    "\n",
    "model = MultitaskClassifier([class_task, rgb_task])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is constructed, we can train it as we would a single-task model, using the `fit` method of a `Trainer` object. The `Trainer` supports multiple schedules or patterns for sampling from different dataloaders; the default is to randomly sample from them proportional to the number of batches, such that all data points will be seen exactly once before any are seen twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciscogonzalez/miniconda3/envs/cerbero-dev/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/franciscogonzalez/miniconda3/envs/cerbero-dev/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/franciscogonzalez/miniconda3/envs/cerbero-dev/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/franciscogonzalez/miniconda3/envs/cerbero-dev/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/franciscogonzalez/miniconda3/envs/cerbero-dev/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/franciscogonzalez/miniconda3/envs/cerbero-dev/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc29d2d858a40d283754a490faa64f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 0:', max=1447.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1add5603a9024c8a87e3f8867c4713f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1:', max=1447.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e97ffa85d74733a3c2da260a289c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2:', max=1447.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493775943cef4bdaac799356709363fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3:', max=1447.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b35287a853b4affa870806bff42891c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4:', max=1447.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b953e945764d416eacb7faef01d822bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5:', max=1447.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdebb5638b0f4ae2b6b5cf365b01a81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 6:', max=1447.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2bcc97961049fca313ccf7e8f8fdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 7:', max=1447.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bc32ead70a4a478ca6534df2d9e42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 8:', max=1447.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dcb9d1c03844c691d119c8dd50dfce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 9:', max=1447.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c35a33dcbbe40479c36d4b9b1d29046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 10:', max=1447.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be8229373354137847b243bb9709e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 11:', max=1447.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c9579bccd64e339c9ebae47067dffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 12:', max=1447.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a83d8a69bb4ffb855dc8ac37a44303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 13:', max=1447.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd30c873f4e4ef2b0034aecf83f2081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 14:', max=1447.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cerbero.trainer import Trainer\n",
    "\n",
    "trainer_config = {\n",
    "    \"progress_bar\": True,\n",
    "    \"n_epochs\": 15,\n",
    "    \"lr\": 2e-3,\n",
    "    \"checkpointing\": True\n",
    "}\n",
    "\n",
    "trainer = Trainer(**trainer_config)\n",
    "trainer.fit(model, dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we can call the `model.score()` method to see the final performance on all tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_task/classDataset/train/accuracy': 0.701978947368421,\n",
       " 'class_task/classDataset/valid/accuracy': 0.5248,\n",
       " 'class_task/classDataset/test/accuracy': 0.5504,\n",
       " 'rgb_task/rgbDataset/train/mse': 0.010030863,\n",
       " 'rgb_task/rgbDataset/valid/mse': 0.010207401,\n",
       " 'rgb_task/rgbDataset/test/mse': 0.010362439}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = dataset.data[:16]\n",
    "rgb_labels = images.mean(axis=(1,2))\n",
    "class_labels = dataset.targets[:16]\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "torch_images, _ = next(dataiter)\n",
    "norm_rgb_labels = torch_images.mean(dim=(2,3))\n",
    "\n",
    "norm_transform = transforms.Normalize(\n",
    "    (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    ")\n",
    "norm_images = torch.stack(\n",
    "    [\n",
    "        norm_transform(torch.Tensor(_image))\n",
    "        for _image in torch_images\n",
    "    ],\n",
    "    dim=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    \"class_data\": norm_images,\n",
    "    \"rgb_data\": norm_images\n",
    "}\n",
    "with torch.no_grad():\n",
    "    out_dict = model(input_dict, task_names=[\"class_task\", \"rgb_task\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_out = torch.argmax(\n",
    "    F.softmax(out_dict[\"class_head\"], dim=1),\n",
    "    dim=1\n",
    ")\n",
    "rgb_out = out_dict[\"rgb_head\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_head\n",
      "y_true: [3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8]\n",
      "y_pred: [3, 9, 0, 8, 4, 6, 2, 6, 3, 1, 0, 9, 5, 7, 9, 9]\n",
      "\n",
      "rgb_head\n",
      "y_true:\n",
      "[[110 111 104]\n",
      " [151 154 161]\n",
      " [121 133 144]\n",
      " [152 151 162]\n",
      " [108 122  92]\n",
      " [135  88  70]\n",
      " [106  62  58]\n",
      " [ 98  98  64]\n",
      " [173 161 144]\n",
      " [138 136 159]\n",
      " [122 143 156]\n",
      " [139 130 128]\n",
      " [106  95  77]\n",
      " [ 77  74  70]\n",
      " [107 112 110]\n",
      " [113 147 122]]\n",
      "y_pred:\n",
      "[[ 85  89  91]\n",
      " [180 181 189]\n",
      " [124 124 121]\n",
      " [169 175 186]\n",
      " [102 106  73]\n",
      " [117 109  98]\n",
      " [ 87  80  74]\n",
      " [148 140 122]\n",
      " [140 133 113]\n",
      " [121 125 128]\n",
      " [125 139 148]\n",
      " [153 141 139]\n",
      " [ 95  89  81]\n",
      " [103  99  88]\n",
      " [135 130 125]\n",
      " [130 126 125]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"class_head\")\n",
    "print(f\"y_true: {class_labels}\")\n",
    "print(f\"y_pred: {class_out.numpy().tolist()}\")\n",
    "\n",
    "print(f\"\\nrgb_head\")\n",
    "print(f\"y_true:\\n{np.round(rgb_labels).astype(int)}\")\n",
    "print(f\"y_pred:\\n{np.round(rgb_out.numpy()*255).astype(int)}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
